<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Linear Algebra</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="math.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Linear Algebra</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#vector-space">Vector Space</a></li>
<li><a href="#subspace">Subspace</a></li>
<li><a href="#linear-operators">Linear Operators</a>
<ul>
<li><a href="#invariant-subspace">Invariant Subspace</a></li>
<li><a href="#eigenvectorsvalues">Eigenvectors/values</a></li>
<li><a href="#jordan-canonical-form">Jordan Canonical Form</a></li>
</ul></li>
</ul>
</nav>
<p>Linear algebra is the study of linear structures and functions that
preserve this structure. Vector spaces are a mathematical sweet spot.
They are completely characterized by their dimension.</p>
<h2 id="vector-space">Vector Space</h2>
<p>A <em>vector space</em> over a <em>field</em> <span
class="math inline">\boldsymbol{F}</span> is set <span
class="math inline">V</span> with a binary operation <span
class="math inline">V\times V\to V</span>, <span
class="math inline">(v,w)\mapsto v + w</span>, and a scalar product
<span class="math inline">\boldsymbol{F}\times V\to V</span>, <span
class="math inline">(a,v)\mapsto av</span>, satisfying the distributive
law. The binary addition is <em>commutative</em> (<span
class="math inline">v + w = w + v</span>), <em>associative</em> (<span
class="math inline">(u + v) + w = u + (w + v)</span>), has an
<em>identity element</em> <span
class="math inline">\boldsymbol{0}</span> (<span class="math inline">v +
\boldsymbol{0}= v</span>), and each element has an inverse (<span
class="math inline">v + (-v) = \boldsymbol{0}</span>). The scalar
product satisfies the <em>distributive laws</em> <span
class="math inline">a(v + w) = av + aw</span>, <span
class="math inline">(a + b)v = av + bv</span>, <span
class="math inline">(ab)v = a(bv)</span>, <span
class="math inline">a,b\in\boldsymbol{F}</span>, <span
class="math inline">v,w\in V</span>. We also require <span
class="math inline">1v = v</span> and <span class="math inline">av =
va</span> for <span class="math inline">a\in\boldsymbol{F}</span> and
<span class="math inline">v\in V</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v + z =
v</span> for all <span class="math inline">v\in V</span> then <span
class="math inline">z = \boldsymbol{0}</span></em>.</p>
<p>This shows the additive identity is unique.</p>
<details>
<summary>
Solution
</summary>
Taking <span class="math inline">v = \boldsymbol{0}</span>, <span
class="math inline">z = \boldsymbol{0}+ z = \boldsymbol{0}</span>.
</details>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v + v =
v</span> then <span class="math inline">v =
\boldsymbol{0}</span></em>.</p>
<p><em>Hint</em>: <span class="math inline">v + (-v) =
\boldsymbol{0}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">0v =
\boldsymbol{0}</span>, <span class="math inline">a\boldsymbol{0}=
\boldsymbol{0}</span>, and <span class="math inline">(-1)v = -v</span>,
<span class="math inline">a\in\boldsymbol{F}</span>, <span
class="math inline">v\in V</span></em>.</p>
<details>
<summary>
Solution
</summary>
Note <span class="math inline">0v + 0v = (0 + 0)v = 0v</span> so <span
class="math inline">0v = \boldsymbol{0}</span>. If <span
class="math inline">a\not=0</span> then for any <span
class="math inline">v\in V</span> we have <span class="math inline">v +
a\boldsymbol{0}= aa^{-1}v + a\boldsymbol{0}= a(a^{-1}v + \boldsymbol{0})
= aa^{-1}v = v</span> so <span class="math inline">a\boldsymbol{0}=
\boldsymbol{0}</span> since the identity is unique. Since <span
class="math inline">v + (-1)v = 1v + (-1)v = (1 + (-1))v) = 0v =
\zore</span> we have <span class="math inline">(-1)v = -v</span>.
</details>
<p>If <span class="math inline">S</span> is any set then the set of all
functions from <span class="math inline">S</span> to the real numbers,
<span class="math inline">\boldsymbol{F}^S = \{v\colon
S\to\boldsymbol{F}\}</span>, is a vector space. The addition is defined
pointwise <span class="math display">
    (v + w)(s) = v(s) + w(s)\text{ for } v, w\in\boldsymbol{F}^S
</span> as is the scalar product <span class="math display">
    (av)(s) = av(s)\text{ for } a\in\boldsymbol{F},
v\in\boldsymbol{F}^S.
</span></p>
<p>The additive identity, <span
class="math inline">\boldsymbol{0}</span>, is the function <span
class="math inline">\boldsymbol{0}(s) = 0</span> for all <span
class="math inline">s\in S</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\boldsymbol{F}^S</span> is a vector space</em>.</p>
<p>We will see later that every vector space has this form. The
cardinality of <span class="math inline">S</span> is the
<em>dimension</em> of the vector space.</p>
<!--

__Exercise__. (Abelian group under addition) _For $u, v, w\in\RR^S$ prove_
$$
\begin{aligned}
\text{(commutative)}\quad&& v + w &= w + v \\
\text{(associative)}\quad&& (u + v) + w &= u + (w + v)  \\
\text{(identity)}\quad&& \zero + v = &\ v = v + \zero \\
\text{(inverse)}\quad&& (-v) + v = &\ \zero = v + (-v) \\
\end{aligned}
$$

_Hint_: $\RR$ is a abelian group under addition.

__Exercise__. (Scalar multiplication) _For $v\in\RR^S$ and $a,b\in\RR$ prove_
$$
\begin{aligned}
0v &= \zero \\
1v &= v \\
(ab)v &= a(bv) \\
\end{aligned}
$$

__Exercise__. (Distributive laws) _For $a,b\in\RR$ and $v,w\in\RR^S$ prove_
$$
\begin{aligned}
a(v + w) &= av + aw \\
(a + b)v &= av + bv \\
\end{aligned}
$$

<details>
<summary>Solution</summary>
We have $(a(v + w))(s) = a((v + w)(s)) = a(v(s) + w(s)) = av(s) + aw(s) = (av + aw)(s)$
and $(a + b)v(s) = av(s) + bv(s)$, $s\in S$,
by the distributive law for real numbers.
</details>
-->
<p>You are probably already familiar with the vector space <span
class="math inline">\boldsymbol{R}^n = \{(x_1,\ldots,x_n)\mid
x_i\in\boldsymbol{R}, 1\le i\le n\}</span>. If <span
class="math inline">S = \{1,\ldots,n\}</span> and <span
class="math inline">x\in\boldsymbol{R}^S</span> then <span
class="math inline">x(i) = x_i</span> provides a correspondance between
<span class="math inline">\boldsymbol{R}^{\{1,\ldots,n\}}</span> and
<span class="math inline">\boldsymbol{R}^n</span>. The <em>Kronecker
delta</em> is <span class="math inline">\delta_{ij} = 1</span> if <span
class="math inline">i = j</span> and <span
class="math inline">\delta_{ij} = 0</span> if <span
class="math inline">i \not= j</span>. The <em>standard basis</em> in
<span class="math inline">\boldsymbol{R}^n</span> is <span
class="math inline">\{e_j\}_{1\le j\le n}\subset\boldsymbol{R}^n</span>
where <span class="math inline">(e_j)_i = \delta_{ij}</span>, <span
class="math inline">1\le i\le n</span>.</p>
<p><strong>Exercise</strong>. <em>Show every vector <span
class="math inline">x = (x_1,\ldots,x_n)\in\boldsymbol{R}^n</span> can
be written using the standard basis as <span class="math inline">x =
\sum_j x_j e_j</span></em>.</p>
<p>In what follows we will use the field <span
class="math inline">\boldsymbol{C}</span> of <em>complex numbers</em> to
make things simpler.</p>
<h2 id="subspace">Subspace</h2>
<p>A subset <span class="math inline">W\subseteq V</span> is a
<em>subspace</em> of <span class="math inline">V</span> if <span
class="math inline">W</span> is also a vector space. Clearly <span
class="math inline">\{\boldsymbol{0}\}</span> is the smallest subspace
and <span class="math inline">V</span> is the largest subspace of <span
class="math inline">V</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v\in
V</span> then <span class="math inline">\boldsymbol{C}v = \{av\mid
a\in\boldsymbol{C}\}</span> is a subspace</em>.</p>
<p>Given any set <span class="math inline">S\subset V</span> define
<span class="math inline">\operatorname{span}S</span> to be the smallest
subspace containing <span class="math inline">S</span>.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">S\subseteq V</span> then <span
class="math inline">\operatorname{span}S = \{\sum_{s\in S_0} a_s s\mid
a_s\in\boldsymbol{C}, S_0\subseteq S \text{ finite }\}</span></em>.</p>
<p>We need <span class="math inline">S_0</span> to be finite for the sum
to be defined when <span class="math inline">S</span> is infinite.</p>
<details>
<summary>
Solution
</summary>
Taking <span class="math inline">S_0 = \{s\}</span> and <span
class="math inline">a_s = 1</span> we see <span
class="math inline">S</span> is a subset of the right hand side. Every
term of the form <span class="math inline">\sum_{s\in S_0} a_s s</span>
must belong to <span class="math inline">\operatorname{span}S</span>.
Since the right hand side is a subspace it must be equal to the span of
<span class="math inline">S</span>.
</details>
<p>A set of vectors <span class="math inline">\{v_i\}_{i\in I}</span>
are <em>independent</em> if every finite sum <span
class="math inline">\sum_i a_i v_i = 0</span> implies <span
class="math inline">a_i = 0</span> for all <span
class="math inline">i</span>. A <em>basis</em> of a vector space is a
set of independent vectors that span <span
class="math inline">V</span>.</p>
<h2 id="linear-operators">Linear Operators</h2>
<p>A <em>linear operator</em> from the vector space <span
class="math inline">V</span> to the vector space <span
class="math inline">W</span>, <span class="math inline">T\colon V\to
W</span>, is a function that preserves the vector space structure: <span
class="math inline">T(u + v) = Tu + Tv</span> and <span
class="math inline">T(au) = aTu</span> for <span
class="math inline">u,v\in V</span>, and <span
class="math inline">a\in\boldsymbol{C}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">T(au +
v) = aTu + v</span>, <span
class="math inline">a\in\boldsymbol{C}</span>, <span
class="math inline">u,v\in V</span> implies <span
class="math inline">T</span> is a linear operator</em>.</p>
<p>The values of a linear transformation on a basis determine the linear
transformation. If <span class="math inline">\{v_i\}</span> is a basis
of <span class="math inline">V</span> then for every <span
class="math inline">v\in V</span> there exist unique <span
class="math inline">x_i\in\boldsymbol{C}</span> with <span
class="math inline">v = \sum_i x_i v_i</span> hence <span
class="math inline">Tv = \sum_i x_i Tv_i</span>.</p>
<p>If <span class="math inline">\{w_j\}</span> is a basis of <span
class="math inline">W</span> then <span class="math inline">Tv_i =
\sum_j t_{ij }w_j</span> for some <span
class="math inline">t_{ij}\in\boldsymbol{C}</span> so <span
class="math inline">T</span> is represented by a matrix <span
class="math inline">(t_{ij})</span> given bases of <span
class="math inline">V</span> and <span class="math inline">W</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">S\colon
U\to V</span> and <span class="math inline">T\colon V\to W</span> are
linear transformations represented by <span
class="math inline">(s_{ij})</span> and <span
class="math inline">(t_{jk})</span> respectively, then <span
class="math inline">TS\colon U\to W</span> is represented by <span
class="math inline">(\sum_j s_{ij} t_{jk})</span></em>.</p>
<p>Matrix multiplication is composition of linear operators.</p>
<details>
<summary>
Solution
</summary>
Let <span class="math inline">\{u_i\}</span> be a basis of <span
class="math inline">U</span>, <span class="math inline">\{v_j\}</span>
be a basis of <span class="math inline">V</span>, and <span
class="math inline">\{w_k\}</span> be a basis of <span
class="math inline">W</span>. We have <span class="math display">
(TS)u_i = T(\sum_j s_{ij} v_j)
    = \sum_j s_{ij} Tv_j
    = \sum_j s_{ij} \sum_k t_{jk} w_k
    = \sum_k (\sum_j s_{ij} t_{jk}) w_k.
</span>
</details>
<p>Note how working in terms of a basis can be tedious.</p>
<p>If a linear operator <span class="math inline">T\colon V\to W</span>
is one-to-one and onto then <span class="math inline">T</span> is an
<em>isomorphism</em>. <em>One-to-one</em> means <span
class="math inline">Tu = Tv</span> implies <span class="math inline">u =
v</span> and <em>onto</em> means for every <span
class="math inline">w\in W</span> there exists <span
class="math inline">v\in V</span> with <span class="math inline">Tv =
w</span>. The inverse of such an operator is defined by <span
class="math inline">T^{-1}w = v</span> if and only if <span
class="math inline">Tv = w</span>, just as for any function.</p>
<p>We say <span class="math inline">V</span> and <span
class="math inline">W</span> are isomorphic and write <span
class="math inline">V\cong W</span>. Isomorphism is an <em>equivalence
relation</em> on vector spaces.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">V\cong
V</span>, <span class="math inline">V\cong W</span> implies <span
class="math inline">W\cong V</span>, and <span
class="math inline">U\cong V</span>, <span class="math inline">V\cong
W</span> imply <span class="math inline">U\cong W</span></em>.</p>
<details>
<summary>
Solution
</summary>
The identity function <span class="math inline">I\colon V\to V</span> is
an isomorphism. If <span class="math inline">T\colon V\to W</span> is an
isomorphism then so is <span class="math inline">T^{-1}\colon W\to
V</span>. If <span class="math inline">S\colon U\to V</span> and <span
class="math inline">T\colon V\to W</span> are isomorphisms then so is
the composition <span class="math inline">TS\colon U\to W</span>.
</details>
<p>The fundamental theorem of linear algebra is that two vector spaces
are isomorphic if and only if they have the same dimension. The
non-trivial proof of this is omitted.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">R\subseteq S\times S</span> is an equivlence
relation then <span class="math inline">\{Rs\mid s\in S\}</span> and
<span class="math inline">\{sR\mid s\in S\}</span> are partitions of
<span class="math inline">S</span></em>.</p>
<p><em>Hint</em>: Recall <span class="math inline">Rs = \{t\in S\mid
(t,s)\in R\}</span> and <span class="math inline">sR = \{t\in S\mid
(s,t)\in R\}</span>.</p>
<p>Vector spaces are classified upto isomorphism by their dimension.</p>
<h3 id="invariant-subspace">Invariant Subspace</h3>
<p>If <span class="math inline">T\colon V\to V</span> is a linear
operator and <span class="math inline">U</span> is a subspace of <span
class="math inline">V</span> then it is <em>invariant</em> under <span
class="math inline">T</span> if <span class="math inline">TW\subseteq
W</span>.</p>
<p>The set of all linear operators from a vector space <span
class="math inline">V</span> to a vector space <span
class="math inline">W</span>, <span
class="math inline">\mathcal{L}(V,W)</span>, is also a vector space. The
addition is defined by <span class="math inline">(S + T)v = Sv +
Tv</span>, <span class="math inline">S,T\in\mathcal{L}(V,W)</span>,
<span class="math inline">v\in V</span> and scalar multiplication by
<span class="math inline">(aT)v = a(Tv)</span>, <span
class="math inline">a\in\boldsymbol{C}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\mathcal{L}(V,W)</span> is a vector space</em>.</p>
<p>The <em>kernel</em> of a linear transformation <span
class="math inline">T\colon V\to W</span> is <span
class="math inline">\operatorname{ker}T = \{v\in V\mid Tv = 0\}</span>
and the <em>range</em> is <span class="math inline">\operatorname{ran}T
= \{Tv\mid v\in V\} \subseteq W</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to W</span> is a linear operator show the kernel is a subspace of
<span class="math inline">V</span> and the range is a subspace of <span
class="math inline">W</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\operatorname{ker}T = \{\boldsymbol{0}\}</span>
implies <span class="math inline">T</span> is one-to-one</em>.</p>
<p><em>Hint</em>: Show <span class="math inline">Tu = Tv</span> imples
<span class="math inline">u = v</span>, <span class="math inline">u,v\in
V</span>.</p>
<p>If <span class="math inline">T\colon V\to W</span> is one-to-one we
can define the inverse <span
class="math inline">T^{-1}\colon\operatorname{ran}T\to V</span> by <span
class="math inline">T^{-1}w = v</span> if and only if <span
class="math inline">w = Tv</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to V</span> is a linear operator then the kernel and range are
invariant under <span class="math inline">T</span></em>.</p>
<details>
<summary>
Solution
</summary>
We have <span class="math inline">T(\operatorname{ker}T) =
\{\boldsymbol{0}\}\subseteq\operatorname{ker}T</span> and <span
class="math inline">T(\operatorname{ran}T) = T(TV)\subseteq TV =
\operatorname{ran}T</span>.
</details>
<p>If <span class="math inline">v_1, \ldots, v_n</span> is a basis for
<span class="math inline">V</span> we can define a linear operator <span
class="math inline">T\colon V\to \boldsymbol{C}^n</span> by <span
class="math inline">Tv_i = e_i</span> where <span
class="math inline">\{e_i\}</span> is the standard basis of <span
class="math inline">\boldsymbol{C}^n</span>. By linearity <span
class="math inline">T(\sum_i a_i v_i) = \sum_i a_i e_i =
(a_1,\ldots,a_n)\in\boldsymbol{C}^n</span>.</p>
<p><strong>Exercise</strong> <em>Show <span class="math inline">T</span>
is one-to-one and onto</em>.</p>
<p><em>Hint</em>: <em>Onto</em> means <span
class="math inline">\operatorname{ran}T = \boldsymbol{C}^n</span>.</p>
<h3 id="eigenvectorsvalues">Eigenvectors/values</h3>
<p>If <span class="math inline">T\colon V\to V</span> is a linear
operator and <span class="math inline">\boldsymbol{C}v</span> is
invariant under <span class="math inline">T</span> for some <span
class="math inline">v\not=\boldsymbol{0}</span> then <span
class="math inline">v</span> is an <em>eigenvector</em> of <span
class="math inline">T</span>. The number <span
class="math inline">\lambda\in\boldsymbol{C}</span> with <span
class="math inline">Tv = \lambda v</span> is the <em>eigenvalue</em>
corresponding to <span class="math inline">v</span>. Note if <span
class="math inline">Tv = \lambda v</span> then <span
class="math inline">v\in\operatorname{ker}T - \lambda I\neq \{0\}</span>
and so <span class="math inline">T - \lambda I</span> is not
invertible.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v</span>
and <span class="math inline">w</span> are eigenvectors with eigenvalue
<span class="math inline">\lambda</span> then so is <span
class="math inline">v + w</span></em>.</p>
<p><em>Hint</em>: <span class="math inline">\operatorname{ker}T -
\lambda I</span> is a subspace.</p>
<p>The <em>spectrum</em> of an operator is the set <span
class="math inline">\sigma(T) = \{\lambda\in\boldsymbol{C}\mid T -
\lambda I\text{ is not invertable}\}</span>. In finite dimensions it is
equal to the set of eigenvaluse.</p>
<p>If <span class="math inline">V =
\boldsymbol{C}^{\boldsymbol{N}}</span> where <span
class="math inline">\boldsymbol{N}= \{0, 1, 2, \ldots\}</span> are the
natural numbers define the <em>forward shift operator</em> <span
class="math inline">S\colon V\to V</span> by <span
class="math inline">S(v_0, v_1, v_2, \ldots) = (0, v_0, v_1,
\ldots)</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">Sv =
\lambda v</span> then <span class="math inline">v =
\boldsymbol{0}</span></em>.</p>
<details>
<summary>
Solution
</summary>
Note <span class="math inline">S</span> is one-to-one so <span
class="math inline">Sv = 0</span> implies <span class="math inline">v =
0</span> and we can assume <span
class="math inline">\lambda\not=0</span>. If <span
class="math inline">Sv = \lambda v</span> then <span
class="math inline">(0, v_0, v_1,\dots) = (\lambda v_0, \lambda v_1,
\lambda v_2,\ldots)</span>. This implies <span class="math inline">0 =
\lambda v_0</span> so <span class="math inline">v_0 = 0</span>. Likewise
<span class="math inline">0 = v_0 = \lambda v_1</span> so <span
class="math inline">v_1 = 0</span>. By induction <span
class="math inline">v_j = 0</span> for all <span
class="math inline">j</span> so <span class="math inline">v =
\boldsymbol{0}</span>.
</details>
<p>This shows <span class="math inline">S</span> has no
eigenvectors.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\sigma(S) = \{\lambda\in\boldsymbol{C}\mid |\lambda|
\le 1\}</span></em>.</p>
<p><em>Hint</em>: If <span class="math inline">|\lambda| &gt; 1</span>
then <span class="math inline">(\lambda I - S)^{-1} = I/\lambda +
S/\lambda^2 + S^2/\lambda^3 + \cdots</span>.</p>
<p>We can also define the shift operator <span class="math inline">J =
J^n</span> on <span class="math inline">\boldsymbol{C}^n</span> by <span
class="math inline">J(x_1,\ldots,x_n) = (0,
x_1,\ldots,x_{n-1})</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">e_n</span> is the only eigenvector and it has
eigenvalue <span class="math inline">0</span></em>.</p>
<p>Note <span class="math inline">J^2(x_1,\ldots,x_n) = (0, 0,
x_1,\ldots,x_{n-2})</span> has eigenvectors <span
class="math inline">e_{n-1}</span> and <span
class="math inline">e_n</span>. Likewise, <span
class="math inline">J^k</span> has eigenvectors <span
class="math inline">e_{n-k+1},\ldots,e_n</span>, <span
class="math inline">1\le k\le n</span>. Clearly <span
class="math inline">J^n = \boldsymbol{0}</span>, the zero operator.</p>
<p>It is not hard to show <span class="math inline">\sigma(J) = 0</span>
but we can use the <em>spectal mapping theorem</em> to give a simple
proof. If <span class="math inline">p</span> is a polynomial and <span
class="math inline">T\colon V\to V</span> is a linear operator then
<span class="math inline">p(T)\colon V\to V</span> can be defined.</p>
<p><strong>Theorem</strong>. (Spectral mapping theorem) _If <span
class="math inline">p</span> is a polynomial then <span
class="math inline">p(\sigma(T)) = \sigma(p(T))</span>.</p>
<p><em>Proof</em>: For any <span
class="math inline">\lambda\in\boldsymbol{C}</span> <span
class="math inline">p(z) - p(\lambda) = (z - \lambda)q(z)</span> for
some polynomial <span class="math inline">q</span>. If <span
class="math inline">\lambda\in\sigma(T)</span> then <span
class="math inline">P(T) - p(\lambda)I = (T - \lambda I)q(T)</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to V</span> and <span class="math inline">T^m = 0</span> for some
<span class="math inline">m</span> then <span
class="math inline">\sigma(T) = \{0\}</span></em>.</p>
<details>
<summary>
Solution
</summary>
Using the spectral mapping theorem we have <span
class="math inline">\{0\} = \sigma(T^m) = \sigma(T)^m</span>. If <span
class="math inline">0 = \lambda^m</span> then <span
class="math inline">\lambda = 0</span>.
</details>
<h3 id="jordan-canonical-form">Jordan Canonical Form</h3>
<p>Suppose <span class="math inline">T\colon V\to V</span> is a linear
operator on an <span class="math inline">n</span>-dimensional space
<span class="math inline">V</span>. For <span class="math inline">v\in
V</span> define its <em>order</em>, $o(v), to be the minimum <span
class="math inline">m</span> such that <span class="math inline">v, Tv,
\ldots T^mv</span> are linearly dependent. If <span
class="math inline">o(v)</span> equals the dimension of <span
class="math inline">V</span> then <span class="math inline">v</span> is
a <em>cyclic vector</em> for <span class="math inline">T</span> and
<span class="math inline">T^n v = \sum_{0\le j&lt; n}a_j T^jv</span> for
some <span class="math inline">a_j\in\boldsymbol{C}</span>. Using the
basis <span class="math inline">v</span>, <span
class="math inline">Tv</span>, , <span
class="math inline">T^{n-1}v</span> gives a representation for <span
class="math inline">T</span> as a matrix.</p>
<p><span class="math inline">T(\sum_j a_j T_j) = \sum_j
a_jT^{j+1}</span></p>
<p>and <span class="math inline">\sigma(T) = \{0\}</span>. For any <span
class="math inline">v\in V</span> the vectors <span
class="math inline">v</span>, <span class="math inline">Tv</span>, ,
<span class="math inline">T^n</span> are linearly dependent so <span
class="math inline">p(T)v = 0</span> from some polynomial <span
class="math inline">p</span>.</p>
<p>Given <span class="math inline">v_1,\ldots,v_n\in V</span> define the
<em>shift operator</em> <span class="math inline">J\colon V\to V</span>
by <span class="math inline">Jv_i = v_{i+1}</span>, <span
class="math inline">1\le j &lt; n</span> and <span
class="math inline">Jv_n = \boldsymbol{0}</span>.</p>
</body>
</html>
