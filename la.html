<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Linear Algebra</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="math.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Linear Algebra</h1>
</header>
<p>Linear algebra is the study of linear structures and functions that
preserve this structure. Vector spaces are a mathematical sweet spot.
They are completely characterized by their dimension. Every vector space
is isomorphic to <span class="math inline">\boldsymbol{R}^n</span> where
<span class="math inline">n</span> is the dimension.</p>
<h2 id="vector-space">Vector Space</h2>
<p>A <em>vector space</em> over the real numbers <span
class="math inline">\boldsymbol{R}</span> is set <span
class="math inline">V</span> with a binary operation <span
class="math inline">V\times V\to V</span>, <span
class="math inline">(v,w)\mapsto v + w</span>, and a scalar product
<span class="math inline">\boldsymbol{R}\times V\to V</span>, <span
class="math inline">(a,v)\mapsto av</span>, satisfying the distributive
law. The binary addition is <em>commutative</em> (<span
class="math inline">v + w = w + v</span>), <em>associative</em> (<span
class="math inline">(u + v) + w = u + (w + v)</span>), has an
<em>identity element</em> <span
class="math inline">\boldsymbol{0}</span> (<span class="math inline">v +
\boldsymbol{0}= v</span>), and each element has an inverse (<span
class="math inline">v + (-v) = \boldsymbol{0}</span>). The scalar
product satisfies the <em>distributive laws</em> <span
class="math inline">a(v + w) = av + aw</span>, <span
class="math inline">(a + b)v = av + bv</span>, <span
class="math inline">(ab)v = a(bv)</span>, <span
class="math inline">a,b\in\boldsymbol{R}</span>, <span
class="math inline">v,w\in V</span>. We also require <span
class="math inline">1v = v</span> and <span class="math inline">av =
va</span> for <span class="math inline">a\in\boldsymbol{R}</span> and
<span class="math inline">v\in V</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v + z =
v</span> for all <span class="math inline">v\in V</span> then <span
class="math inline">z = \boldsymbol{0}</span></em>.</p>
<p>This shows the additive identity is unique.</p>
<details>
<summary>
Solution
</summary>
Taking <span class="math inline">v = \boldsymbol{0}</span>, <span
class="math inline">z = \boldsymbol{0}+ z = \boldsymbol{0}</span>.
</details>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v + v =
v</span> then <span class="math inline">v =
\boldsymbol{0}</span></em>.</p>
<p><em>Hint</em>. <span class="math inline">v + (-v) =
\boldsymbol{0}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">0v =
\boldsymbol{0}</span>, <span class="math inline">a\boldsymbol{0}=
\boldsymbol{0}</span>, and <span class="math inline">(-1)v = -v</span>,
<span class="math inline">a\in\boldsymbol{R}</span>, <span
class="math inline">v\in V</span></em>.</p>
<details>
<summary>
Solution
</summary>
Note <span class="math inline">0v + 0v = (0 + 0)v = 0v</span> so <span
class="math inline">0v = \boldsymbol{0}</span>. If <span
class="math inline">a\not=0</span> then for any <span
class="math inline">v\in V</span> we have <span class="math inline">v +
a\boldsymbol{0}= aa^{-1}v + a\boldsymbol{0}= a(a^{-1}v + \boldsymbol{0})
= aa^{-1}v = v</span> so <span class="math inline">a\boldsymbol{0}=
\boldsymbol{0}</span> since the identity is unique. Since <span
class="math inline">v + (-1)v = 1v + (-1)v = (1 + (-1))v) = 0v =
\zore</span> we have <span class="math inline">(-1)v = -v</span>.
</details>
<p>If <span class="math inline">S</span> is any set then the set of all
functions from <span class="math inline">S</span> to the real numbers,
<span class="math inline">\boldsymbol{R}^S = \{v\colon
S\to\boldsymbol{R}\}</span>, is a vector space. The addition is defined
pointwise <span class="math display">
    (v + w)(s) = v(s) + w(s)\text{ for } v, w\in\boldsymbol{R}^S
</span> as is the scalar product <span class="math display">
    (av)(s) = av(s)\text{ for } a\in\boldsymbol{R},
v\in\boldsymbol{R}^S.
</span></p>
<p>The additive identity, <span
class="math inline">\boldsymbol{0}</span>, is the function <span
class="math inline">\boldsymbol{0}(s) = 0</span> for all <span
class="math inline">s\in S</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\boldsymbol{R}^S</span> is a vector space</em>.</p>
<!--

__Exercise__. (Abelian group under addition) _For $u, v, w\in\RR^S$ prove_
$$
\begin{aligned}
\text{(commutative)}\quad&& v + w &= w + v \\
\text{(associative)}\quad&& (u + v) + w &= u + (w + v)  \\
\text{(identity)}\quad&& \zero + v = &\ v = v + \zero \\
\text{(inverse)}\quad&& (-v) + v = &\ \zero = v + (-v) \\
\end{aligned}
$$

_Hint_. $\RR$ is a abelian group under addition.

__Exercise__. (Scalar multiplication) _For $v\in\RR^S$ and $a,b\in\RR$ prove_
$$
\begin{aligned}
0v &= \zero \\
1v &= v \\
(ab)v &= a(bv) \\
\end{aligned}
$$

__Exercise__. (Distributive laws) _For $a,b\in\RR$ and $v,w\in\RR^S$ prove_
$$
\begin{aligned}
a(v + w) &= av + aw \\
(a + b)v &= av + bv \\
\end{aligned}
$$

<details>
<summary>Solution</summary>
We have $(a(v + w))(s) = a((v + w)(s)) = a(v(s) + w(s)) = av(s) + aw(s) = (av + aw)(s)$
and $(a + b)v(s) = av(s) + bv(s)$, $s\in S$,
by the distributive law for real numbers.
</details>
-->
<p>You are probably already familiar with the vector space <span
class="math inline">\boldsymbol{R}^n = \{(x_1,\ldots,x_n)\mid
x_i\in\boldsymbol{R}, 1\le i\le n\}</span>. If <span
class="math inline">S = \{1,\ldots,n\}</span> and <span
class="math inline">x\in\boldsymbol{R}^S</span> then <span
class="math inline">x(i) = x_i</span> provides a correspondance between
<span class="math inline">\boldsymbol{R}^{\{1,\ldots,n\}}</span> and
<span class="math inline">\boldsymbol{R}^n</span>. The <em>Kronecker
delta</em> is <span class="math inline">\delta_{ij} = 1</span> if <span
class="math inline">i = j</span> and <span
class="math inline">\delta_{ij} = 0</span> if <span
class="math inline">i \not= j</span>. The <em>standard basis</em> in
<span class="math inline">\boldsymbol{R}^n</span> is <span
class="math inline">\{e_j\}_{1\le j\le n}\subset\boldsymbol{R}^n</span>
where <span class="math inline">(e_j)_i = \delta_{ij}</span>, <span
class="math inline">1\le i\le n</span>.</p>
<p><strong>Exercise</strong>. <em>Show every vector <span
class="math inline">x = (x_1,\ldots,x_n)\in\boldsymbol{R}^n</span> can
be written using the standard basis as <span class="math inline">x =
\sum_j x_j e_j</span></em>.</p>
<h2 id="subspace">Subspace</h2>
<p>A subset <span class="math inline">W\subseteq V</span> is a
<em>subspace</em> of <span class="math inline">V</span> if <span
class="math inline">W</span> is also a vector space. Clearly <span
class="math inline">\{0\}</span> is the smallest subspace and <span
class="math inline">V</span> is the largest subspace of <span
class="math inline">V</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">v\in
V</span> then <span class="math inline">\boldsymbol{R}v = \{av\mid
a\in\boldsymbol{R}\}</span> is a subspace</em>.</p>
<p>Given any set <span class="math inline">S\subset V</span> define
<span class="math inline">\operatorname{span}S</span> to be the smallest
subspace containing <span class="math inline">S</span>.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">S\subseteq V</span> then <span
class="math inline">\operatorname{span}S = \{\sum_{s\in S_0} a_s s\mid
a_s\in\boldsymbol{R}, S_0\subseteq S \text{ finite }\}</span></em>.</p>
<p>We need <span class="math inline">S_0</span> to be finite for the sum
to be defined.</p>
<details>
<summary>
Solution
</summary>
Taking <span class="math inline">S_0 = \{s\}</span> and <span
class="math inline">a_s = 1</span> we see <span
class="math inline">S</span> is a subset of the right hand side. Every
term of the form <span class="math inline">\sum_{s\in S_0} a_s s</span>
must belong to <span class="math inline">\operatorname{span}S</span>.
Since the right hand side is a subspace it must be equal to the span of
<span class="math inline">S</span>.
</details>
<p>A set of vectors <span class="math inline">\{v_i\}_{i\in I}</span>
are <em>independent</em> if every finite sum <span
class="math inline">\sum_i a_i v_i = 0</span> implies <span
class="math inline">a_i = 0</span> for all <span
class="math inline">i</span>. A <em>basis</em> of a vector space is a
set of independent vectors that span <span
class="math inline">V</span>.</p>
<h2 id="linear-operators">Linear Operators</h2>
<p>A <em>linear operator</em> from the vector space <span
class="math inline">V</span> to the vector space <span
class="math inline">W</span>, <span class="math inline">T\colon V\to
W</span>, is a function that preserves the vector space structure: <span
class="math inline">T(u + v) = Tu + Tv</span> and <span
class="math inline">T(au) = aTu</span> for <span
class="math inline">u,v\in V</span>, and <span
class="math inline">a\in\boldsymbol{R}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">T(au +
v) = aTu + v</span>, <span
class="math inline">a\in\boldsymbol{R}</span>, <span
class="math inline">u,v\in V</span> implies <span
class="math inline">T</span> is a linear operator</em>.</p>
<p>If <span class="math inline">T\colon V\to V</span> is a linear
operator and <span class="math inline">U</span> is a subspace of <span
class="math inline">V</span> then it is <em>invariant</em> under <span
class="math inline">T</span> if <span class="math inline">TW\subseteq
W</span>.</p>
<p>The set of all linear operators from a vector space <span
class="math inline">V</span> to a vector space <span
class="math inline">W</span>, <span
class="math inline">\mathcal{L}(V,W)</span>, is also a vector space. The
addition is defined by <span class="math inline">(S + T)v = Sv +
Tv</span>, <span class="math inline">S,T\in\mathcal{L}(V,W)</span>,
<span class="math inline">v\in V</span> and scalar multiplication by
<span class="math inline">(aT)v = a(Tv)</span>, <span
class="math inline">a\in\boldsymbol{R}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\mathcal{L}(V,W)</span> is a vector space</em>.</p>
<p>The <em>kernel</em> of a linear transformation <span
class="math inline">T\colon V\to W</span> is <span
class="math inline">\operatorname{ker}T = \{v\in V\mid Tv = 0\}</span>
and the <em>range</em> is <span class="math inline">\operatorname{ran}T
= \{Tv\mid v\in V\} \subseteq W</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to W</span> is a linear operator show the kernel is a subspace of
<span class="math inline">V</span> and the range is a subspace of <span
class="math inline">W</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\operatorname{ker}T = \{0\}</span> implies <span
class="math inline">T</span> is one-to-one</em>.</p>
<p><em>Hint</em>: Show <span class="math inline">Tu = Tv</span> imples
<span class="math inline">u = v</span>, <span class="math inline">u,v\in
V</span>.</p>
<p>If <span class="math inline">T\colon V\to W</span> is one-to-one we
can define the inverse <span
class="math inline">T^{-1}\colon\operatorname{ran}T\to V</span> by <span
class="math inline">T^{-1}w = v</span> if and only if <span
class="math inline">w = Tv</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to V</span> is a linear operator then the kernel and range are
invariant under <span class="math inline">T</span></em>.</p>
<details>
<summary>
Solution
</summary>
We have <span class="math inline">T(\operatorname{ker}T) =
\{\boldsymbol{0}\}\subseteq\operatorname{ker}T</span> and <span
class="math inline">T(\operatorname{ran}T) = T(TV)\subseteq TV =
\operatorname{ran}T</span>.
</details>
<p>If <span class="math inline">v_1, \ldots, v_n</span> is a basis for
<span class="math inline">V</span> we can define a linear operator <span
class="math inline">T\colon V\to \boldsymbol{R}^n</span> by <span
class="math inline">Tv_i = e_i</span> where <span
class="math inline">\{e_i\}</span> is the standard basis of <span
class="math inline">\boldsymbol{R}^n</span>. By linearity <span
class="math inline">T(\sum_i a_i v_i) = \sum_i a_i e_i =
(a_1,\ldots,a_n)\in\boldsymbol{R}^n</span>.</p>
<p><strong>Exercise</strong> <em>Show <span class="math inline">T</span>
is one-to-one and onto</em>.</p>
<p><em>Hint</em>. <em>Onto</em> means <span
class="math inline">\operatorname{ran}T = \boldsymbol{R}^n</span>.</p>
<p>If <span class="math inline">T\colon V\to W</span> is one-to-one and
onto then <span class="math inline">T</span> is an <em>isomorphism</em>.
We say <span class="math inline">V</span> and <span
class="math inline">W</span> are isomorphic and write <span
class="math inline">V\cong W</span>. Isomorphism is an <em>equivalence
relation</em> on vector spaces.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">V\cong
V</span>, <span class="math inline">V\cong W</span> implies <span
class="math inline">W\cong V</span>, and <span
class="math inline">U\cong V</span>, <span class="math inline">V\cong
W</span> imply <span class="math inline">U\cong W</span></em>.</p>
<h3 id="eigenvectorsvalues">Eigenvectors/values</h3>
<p>If <span class="math inline">T\colon V\to V</span> is a linear
operator and <span class="math inline">\boldsymbol{R}v</span> is
invariant under <span class="math inline">T</span> then <span
class="math inline">v</span> is an <em>eigenvector</em> of <span
class="math inline">T</span>. The number <span
class="math inline">\lambda\in\boldsymbol{R}</span> with <span
class="math inline">Tv = \lambda v</span> is the <em>eigenvalue</em>
corresponding to <span class="math inline">v</span>. Note if <span
class="math inline">Tv = \lambda v</span> then <span
class="math inline">v\in\operatorname{ker}T - \lambda I\neq \{0\}</span>
and so <span class="math inline">T - \lambda I</span> is not
invertible.</p>
<p>The <em>spectrum</em> of an operator is the set of all eigenvalues:
<span class="math inline">\sigma(T) = \{\lambda\in\boldsymbol{R}\mid
\operatorname{ker}(T - \lambda I) \not=\{\boldsymbol{0}\}\}</span>.</p>
<p>For <span class="math inline">v\in V</span> let <span
class="math inline">V_v = \operatorname{span}\{T^jv\mid j\ge0\}</span>.
Clearly <span class="math inline">V_v</span> is invariant for <span
class="math inline">T</span>.</p>
<p><em>Spectral mapping theorem</em> If <span
class="math inline">p</span> is a polynomial then <span
class="math inline">p(\sigma(T)) = \sigma(p(T))</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to V</span> and <span class="math inline">T^m = 0</span> for some
<span class="math inline">m</span> then <span
class="math inline">\sigma(T) = \{0\}</span></em>.</p>
<details>
<summary>
Solution
</summary>
Using the spectral mapping theorem we have <span
class="math inline">\{0\} = \sigma(T^m) = \sigma(T)^m</span>. If <span
class="math inline">0 = \lambda^m</span> then <span
class="math inline">\lambda = 0</span>.
</details>
<h3 id="jordan-canonical-form">Jordan Canonical Form</h3>
<p>Suppose <span class="math inline">T\colon V\to V</span> is a linear
operator on an <span class="math inline">n</span>-dimensional space
<span class="math inline">V</span>. For <span class="math inline">v\in
V</span> define its <em>order</em>, $o(v), to be the minimum <span
class="math inline">m</span> such that <span class="math inline">v, Tv,
\ldots T^mv</span> are linearly dependent. If <span
class="math inline">o(v)</span> equals the dimension of <span
class="math inline">V</span> then <span class="math inline">v</span> is
a <em>cyclic vector</em> for <span class="math inline">T</span> and
<span class="math inline">T^n v = \sum_{0\le j&lt; n}a_j T^jv</span> for
some <span class="math inline">a_j\in\boldsymbol{R}</span>. Using the
basis <span class="math inline">v</span>, <span
class="math inline">Tv</span>, , <span
class="math inline">T^{n-1}v</span> gives a representation for <span
class="math inline">T</span> as a matrix.</p>
<p><span class="math inline">T(\sum_j a_j T_j) = \sum_j
a_jT^{j+1}</span></p>
<p>and <span class="math inline">\sigma(T) = \{0\}</span>. For any <span
class="math inline">v\in V</span> the vectors <span
class="math inline">v</span>, <span class="math inline">Tv</span>, ,
<span class="math inline">T^n</span> are linearly dependent so <span
class="math inline">p(T)v = 0</span> from some polynomial <span
class="math inline">p</span>.</p>
<p>Given <span class="math inline">v_1,\ldots,v_n\in V</span> define the
<em>shift operator</em> <span class="math inline">J\colon V\to V</span>
by <span class="math inline">Jv_i = v_{i+1}</span>, <span
class="math inline">1\le j &lt; n</span> and <span
class="math inline">Jv_n = \boldsymbol{0}</span>.</p>
</body>
</html>
